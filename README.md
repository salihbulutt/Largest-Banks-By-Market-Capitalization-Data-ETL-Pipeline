# GDP Data ETL Pipeline

A robust ETL (Extract, Transform, Load) pipeline that scrapes GDP data from Wikipedia, transforms it, and stores it in both CSV and SQLite database formats.

## ğŸ“‹ Table of Contents

- [Overview](#dart-overview)
- [Features](#features)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Pipeline Workflow](#pipeline-workflow)
- [Configuration](#configuration)
- [Output Files](#output-files)
- [Query Examples](#query-examples)
- [Logging](#logging)
- [Contributing](#contributing)
- [License](#license)

## ğŸ¯Overview

This project demonstrates a complete ETL pipeline that:
- **Extracts** GDP data from Wikipedia's archived page
- **Transforms** the data from millions to billions USD
- **Loads** the processed data into CSV and SQLite database
- **Logs** every step of the process with timestamps

## âœ¨ Features

- âœ… Web scraping with Beautiful Soup
- âœ… Data transformation and cleaning with Pandas
- âœ… Dual output: CSV and SQLite database
- âœ… Comprehensive logging system
- âœ… SQL query execution capability
- âœ… Error handling and data validation

## ğŸ“¦ Prerequisites

- Python 3.7 or higher
- pip (Python package manager)

## ğŸš€ Installation

### Step 1: Clone the Repository

```bash
git clone https://github.com/yourusername/gdp-etl-pipeline.git
cd gdp-etl-pipeline
```

### Step 2: Create Virtual Environment (Recommended)

**Windows:**
```bash
python -m venv venv
venv\Scripts\activate
```

**macOS/Linux:**
```bash
python3 -m venv venv
source venv/bin/activate
```

### Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

## ğŸ’» Usage

### Basic Usage

Run the ETL pipeline:

```bash
python etl_pipeline.py
```

### Advanced Usage

You can modify the configuration in `config.py` or pass parameters directly in the script.

## ğŸ“ Project Structure

```
gdp-etl-pipeline/
â”‚
â”œâ”€â”€ etl_pipeline.py           # Main ETL script
â”œâ”€â”€ config.py                 # Configuration settings
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ README.md                 # Project documentation
â”œâ”€â”€ .gitignore               # Git ignore rules
â”œâ”€â”€ LICENSE                  # License file
â”‚
â”œâ”€â”€ data/                    # Output directory (created on first run)
â”‚   â”œâ”€â”€ Countries_by_GDP.csv
â”‚   â””â”€â”€ World_Economies.db
â”‚
â”œâ”€â”€ logs/                    # Logs directory (created on first run)
â”‚   â””â”€â”€ etl_project_log.txt
â”‚
â””â”€â”€ tests/                   # Unit tests (optional)
    â””â”€â”€ test_etl.py
```

## ğŸ”„ Pipeline Workflow

```
1. Extract
   â†“
   Scrape GDP data from Wikipedia Archive
   â†“
2. Transform
   â†“
   Convert millions â†’ billions USD
   Round to 2 decimal places
   â†“
3. Load
   â†“
   Save to CSV
   Save to SQLite Database
   â†“
4. Query & Validate
   â†“
   Execute sample queries
   â†“
5. Log All Steps
```

## âš™ï¸ Configuration

Edit `config.py` to customize:

```python
# Data source
URL = 'https://web.archive.org/web/...'

# Output paths
CSV_PATH = './data/Countries_by_GDP.csv'
DB_NAME = './data/World_Economies.db'

# Database settings
TABLE_NAME = 'Countries_by_GDP'

# Logging
LOG_FILE = './logs/etl_project_log.txt'
```

## ğŸ“Š Output Files

### CSV Output
Located at: `data/Countries_by_GDP.csv`

| Country | GDP_USD_billions |
|---------|------------------|
| United States | 25462.70 |
| China | 17963.17 |
| ... | ... |

### SQLite Database
Located at: `data/World_Economies.db`

Table: `Countries_by_GDP`
- Country (TEXT)
- GDP_USD_billions (REAL)

## ğŸ” Query Examples

The pipeline includes a sample query. You can add more:

```python
# Get countries with GDP >= 100 billion
query = "SELECT * FROM Countries_by_GDP WHERE GDP_USD_billions >= 100"

# Get top 10 countries
query = "SELECT * FROM Countries_by_GDP ORDER BY GDP_USD_billions DESC LIMIT 10"

# Get average GDP
query = "SELECT AVG(GDP_USD_billions) as avg_gdp FROM Countries_by_GDP"
```

## ğŸ“ Logging

All operations are logged with timestamps in `logs/etl_project_log.txt`:

```
2025-Nov-22-14:30:15 : Preliminaries complete. Initiating ETL process
2025-Nov-22-14:30:16 : Data extraction complete. Initiating Transformation process
2025-Nov-22-14:30:16 : Data transformation complete. Initiating loading process
...
```

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¤ Author

Your Name
- GitHub: [@salihbulutt](https://github.com/salihbulutt)
- Email: salihbulut1@gmail.com

## ğŸ™ Acknowledgments

- Data source: Wikipedia
- Built with Python, BeautifulSoup, Pandas, and SQLite

## ğŸ“ˆ Future Enhancements

- [ ] Add unit tests
- [ ] Implement command-line arguments
- [ ] Add data visualization
- [ ] Create REST API endpoint
- [ ] Add Docker support
- [ ] Implement scheduling (cron jobs)

---

**â­ If you find this project helpful, please consider giving it a star!**
